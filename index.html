<!DOCTYPE html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async="" src="./files/js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'G-WYV42QGLZ8');
  </script>

  <meta name="author" content="Jinlong Peng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Jinlong Peng's Homepage.">
  <title>Jinlong Peng</title>

  <link rel="stylesheet" href="./files/font.css">
  <link rel="stylesheet" href="./files/main.css">
  <script src="./files/main.js"></script>
  <script src="./files/scroll.js"></script>
</head>

<body data-new-gr-c-s-check-loaded="14.993.0" data-gr-ext-installed="">
    <div class="outercontainer"> 
      <header>
        <div class="container header">
          <div class="ftheader text"><a href="https://pjl1995.github.io/#home">Home</a></div>
          <div class="ftheader text"><a href="https://pjl1995.github.io/#publications">Publications</a></div>
          <div class="ftheader text"><a href="https://pjl1995.github.io/#educations">Educations</a></div>          
          <div class="ftheader text"><a href="https://pjl1995.github.io/#competitions">Competitions</a></div>          
          <div class="ftheader text"><a href="https://pjl1995.github.io/#honors">Honors</a></div>   
          <div class="ftheader text"><a href="https://pjl1995.github.io/#services">Services</a></div>        
        </div>
      </header>
      <div class="container body">
        <div class="content heading anchor" id="home" data-scroll-id="home" tabindex="-1" style="outline: none;">
          <div class="text info">
            <h1>Jinlong Peng (彭瑾龙)</h1>
            <p>
            </p>
            <div>Senior Researcher</div>
            <div>Tencent Youtu Lab</div>
            <div>Email:&nbsp;jeromepeng@tencent.com</div>
            <p>
            <span><a href="https://scholar.google.com.hk/citations?user=i5I-cIEAAAAJ&hl=zh-CN">Google Scholar</a></span> / 
            <span><a href="https://github.com/pjl1995">Github</a></span> / 
            <span><a href="https://zhihu.com/people/peng-jin-long-47">Zhihu</a></span>
            </p>
            <p>
            </p>
          </div>
          <div class="img"><img class="avatar" src="./imgs/me.jpg" alt="Photo"></div>
          <div class="text info">
            <p>I am currently a Senior Researcher at <a href="https://open.youtu.qq.com/#/open">Tencent Youtu Lab</a>. My research interests are in multiple object tracking, visual object traking, video object segmentation, video instance segmentation, matting, harmonization, computer graphics.
               <br><br>
               I obtained the master's degree at 2019 and bachelor's degree at 2016 both from <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, advised by <a href="https://weiyaolin.github.io/">Prof. Weiyao Lin</a>.
               <br><br>
               <strong>I am looking for highly motivated interns working on exciting computer vision and graphics projects based in Shanghai. If you are interested, please send me an email.</strong>
            </p>
          </div>
        </div>

        <div class="content" style="z-index:1;position:relative">
          <div class="text">
            <h2 style="margin-bottom:.5em">News</h2>
            <ul style="padding-bottom:1em">
              <li><strong>[04/2021]</strong> Paper SiamRCR is accepted by IJCAI 2021.</li> 
              <li><strong>[09/2020]</strong> Paper STM-cycle is accepted by NeurIPS 2020.</li>
              <li><strong>[08/2020]</strong> Paper BPM is accepted by ACM MM 2020. </li>
              <li><strong>[07/2020]</strong> Paper CTracker is accepted by ECCV 2020 (Spotlight).</li>
              <li><strong>[06/2020]</strong> Our BPM wins the 1st place of ACM MM 2020 Grand Challenge HiEve MOT Public Track.</li>
              <li><strong>[05/2020]</strong> Paper TPM is accepted by Pattern Recognition. </li>
              <li><strong>[12/2019]</strong> Our CTracker ranks No.1 on MOT17 private. </li>
              <li><strong>[07/2019]</strong> Our TPM ranks No.1 on MOT16 public and MOT17 public. </li>
              <li><strong>[08/2018]</strong> Paper TSN is accepted by VCIP 2018. </li>
            </ul>
          </div>
        </div>

        <div class="content anchor" id="publications">
          <div class="text" style="z-index:1;position:relative">
            <h2 style="margin-bottom:0em">
              Publications
            </h2>
          </div>
          
          <div id="pubs">
            <div class="text anchor">&nbsp;</div>
            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/SiamRCR.png" alt="SiamRCR"></div>
              <div class="text">
                <div class="title">SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking</div> 
                <div class="authors">
                  <span class="author jw">Jinlong Peng</span>, 
                  <span class="author">Zhengkai Jiang</span>,
                  <span class="author">Yueyang Gu</span>,
                  <span class="author">Yangu Wu</span>, 
                  <span class="author">Yabiao Wang</span>, 
                  <span class="author">Ying Tai</span>,
                  <span class="author">Chengjie Wang</span>,
                  <span class="author">Weiyao Lin</span>
                </div>
                <div>
                  <span class="venue">IJCAI 2021</span> /
                  <span class="tag"><a href="https://arxiv.org/pdf/2105.11237.pdf">Paper</a></span> 
<!--                   <span class="tag"><a href="https://arxiv.org/pdf/2007.03496.pdf">Paper</a></span> / 
                  <span class="tag"><a href="https://megvii-basedetection/AutoAssign">Code</a></span> -->
                </div>
                <br>
                <div>
                  The RCR structure is proposed to alleviate the misalignment of classification and regression in VOT.
                </div>
              </div>
            </div>

            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/STM-cycle.png" alt="STM-cycle"></div>
              <div class="text">
                <div class="title">Delving into the Cyclic Mechanism in Semi-supervised Video Object Segmentation</div> 
                <div class="authors">
                  <span class="author">Yuxi Li*</span>,
                  <span class="author">Ning Xu*</span>,
                  <span class="author jw">Jinlong Peng*</span>, 
                  <span class="author">John See</span>, 
                  <span class="author">Weiyao Lin</span>
                </div>
                <div>
                  <span class="venue">NeurIPS 2020</span> /
                  <span class="tag"><a href="https://proceedings.neurips.cc/paper/2020/file/0d5bd023a3ee11c7abca5b42a93c4866-Paper.pdf">Paper</a></span> / 
                  <span class="tag"><a href="https://github.com/lyxok1/STM-Training">Code</a></span>
                </div>
                <br>
                <div>
                  A cyclic mechanism is incorporated to produce more robust representations in VOS.
                </div>
              </div>
            </div>


            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/BPM.png" alt="BPM"></div>
              <div class="text">
                <div class="title">Dense Scene Multiple Object Tracking with Box-Plane Matching</div> 
                <div class="authors">
                  <span class="author jw">Jinlong Peng</span>, 
                  <span class="author">Yueyang Gu</span>, 
                  <span class="author">Yabiao Wang</span>, 
                  <span class="author">Chengjie Wang</span>,
                  <span class="author">Jilin Li</span>,
                  <span class="author">Feiyue Huang</span>
                </div>
                <div>
                  <span class="venue">ACM MM 2020</span> /
                  <span class="tag"><a href="https://dl.acm.org/doi/pdf/10.1145/3394171.3416283">Paper</a></span> 
                  <!-- <span class="tag"><a href="https://github.com/StevenGrove/LearnableTreeFilterV2">Code</a></span> -->
                </div>
                <br>
                <div>
                  ACM Multimedia Grand Challenge HiEve 2020 MOT Public Track Winner.
                </div>
              </div>
            </div>

            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/CTracker.png" alt="CTracker"></div>
              <div class="text">
                <div class="title">Chained-Tracker: Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking</div> 
                <div class="authors">
                  <span class="author jw">Jinlong Peng</span>,
                  <span class="author">Changan Wang</span>,
                  <span class="author">Fangbin Wan</span>,
                  <span class="author">Yang Wu</span>,
                  <span class="author">Yabiao Wang</span>,
                  <span class="author">Ying Tai</span>,
                  <span class="author">Chengjie Wang</span>,
                  <span class="author">Jilin Li</span>,
                  <span class="author">Feiyue Huang</span>,
                  <span class="author">Yanwei Fu</span>
                </div>
                <div>
                  <span class="venue">ECCV 2020 (Spotlight)</span> /
                  <span class="tag"><a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123490137.pdf">Paper</a></span> / 
                  <span class="tag"><a href="https://github.com/pjl1995/CTracker">Code</a></span> /
                  <span class="tag"><a href="https://www.youtube.com/watch?v=UovwAgKys88">Video</a></span>
                </div>
                <br>
                <div>
                  A novel end-to-end framework with the proposed two-frame input mode in MOT.
                </div>
              </div>
            </div>

            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/TPM.png" alt="TPM"></div>
              <div class="text">
                <div class="title">TPM: Multiple object tracking with tracklet-plane matching</div>
                <div class="authors">
                  <span class="author jw">Jinlong Peng</span>,
                  <span class="author">Tao Wang</span>,
                  <span class="author">Weiyao Lin</span>,
                  <span class="author">Jian Wang</span>, 
                  <span class="author">John See</span>,
                  <span class="author">Shilei Wen</span>,
                  <span class="author">Errui Ding</span>
                </div>
                <div>
                  <span class="venue">Pattern Recognition</span> /
                  <span class="tag"><a href="https://www.researchgate.net/profile/Jinlong-Peng-3/publication/341758170_TPM_Multiple_Object_Tracking_with_Tracklet-Plane_Matching/links/5ef9e5ae45851550507b22f5/TPM-Multiple-Object-Tracking-with-Tracklet-Plane-Matching.pdf">Paper</a></span> 
                  <!-- <span class="tag"><a href="https://github.com/poodarchu/Det3D">Code</a></span> -->
                </div>
                <br>
                <div>
                    The TPM structure is proposed to reduce the interferences from noisy detections in MOT.
                </div>
              </div>
            </div>

            <div class="publication">
              <div class="img"><img class="img_responsive" src="./imgs/TSN.png" alt="TSN"></div>
              <div class="text">
                <div class="title">Tracklet Siamese Network with Constrained Clustering for Multiple Object Tracking</div>
                <div class="authors">
                  <span class="author jw">Jinlong Peng</span>,
                  <span class="author">Fan Qiu</span>,
                  <span class="author">John See</span>,
                  <span class="author">Qi Guo</span>,
                  <span class="author">Shaoshuai Huang</span>,
                  <span class="author">Lingyu Duan</span>,
                  <span class="author">Weiyao Lin</span>
                </div>
                <div>
                  <span class="venue">VCIP 2018</span> /
                  <span class="tag"><a href="https://www.researchgate.net/profile/Jinlong-Peng-3/publication/332682325_Tracklet_Siamese_Network_with_Constrained_Clustering_for_Multiple_Object_Tracking/links/5ef9edf9a6fdcc4ca43a405f/Tracklet-Siamese-Network-with-Constrained-Clustering-for-Multiple-Object-Tracking.pdf">Paper</a></span>
                </div>
                <br>
                <div>
                  The TSN structure is proposed to learn appearance similarities between tracklets in MOT.
                </div>
              </div>
            </div>

        <div class="content anchor" id="educations">
          <div class="text" style="z-index:1;position:relative">
            <h2 style="margin-bottom:0em">
              Educations
            </h2>
          </div>
          <ul>
            <li>[2016.09-2019.03] &nbsp; Shanghai Jiao Tong University.
            <li>[2012.09-2016.06] &nbsp; Shanghai Jiao Tong University.
          </ul>  
        
        <div class="content anchor" id="competitions">
          <div class="text" style="z-index:1;position:relative">
            <h2 style="margin-bottom:0em">
              Competitions
            </h2>
          </div>
          <ul>
            <li>Winner of the ACM Multimedia Grand Challenge HiEve 2020 MOT Public Track.</li>
          </ul>
        
        <div class="content anchor" id="honors">
          <div class="text" style="z-index:1;position:relative">
            <h2 style="margin-bottom:0em">
              Honors
            </h2>
          </div>
          <ul>
            <li><strong>[02/2021]</strong> Technology Construction Award of Tencent Youtu Lab.</li>
            <li><strong>[01/2020]</strong> Outstanding Staff Award of Tencent.</li>
            <li><strong>[03/2019]</strong> Outstanding Graduates of SJTU.</li>
            <li><strong>[10/2018]</strong> First-class Scholarship and Excellent Scholarship of SJTU.</li>
            <li><strong>[12/2017]</strong> The second prize in the 14th China graduate Mathematical Contest in Modeling.</li> 
            <li><strong>[04/2016]</strong> Outstanding Graduates of SJTU.</li>   
            <li><strong>[10/2015]</strong> The Excellence Award in Shanghai Undergraduate Innovative Practice Project.</li>   
            <li><strong>[12/2014]</strong> The first prize in the 23rd China Undergraduate Mathematical Contest in Modeling.</li>
            <li><strong>[10/2013]</strong> National Endeavor Fellowship and Excellent Scholarship of SJTU.</li>
          </ul>

        <div class="content anchor" id="services">
          <div class="text" style="z-index:1;position:relative">
            <h2 style="margin-bottom:0em">
              Services
            </h2>
          </div>
          <ul>
            <li>Conference Reviewer:</li>
                NeurIPS 2021, AAAI 2019 & 2021 & 2022, ACM MM 2020, ICME 2018.<br/>
            <li>Journal Reviewer:</li>
                International Journal of Computer Vision (IJCV), IEEE Transactions On Image Processing (TIP), Pattern Recognition (PR), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), Journal of Visual Communication and Image Representation (JVCI).<br />
            <li>Invitated Report:</li>
                ChinaMM 2020 (Multi Person Motion Tracking in Complex Events).<br />
          </ul>
      </div>  <!-- content -->
    </div> <!-- container -->
  </div> <!-- outer container -->
<script>showPubs(0);</script>
<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
</div><script>mendeleyWebImporter = { open: function () { window.postMessage('0.6076674848300223', 'https://pjl1995.github.io') } }</script><youdao_grammar_result><div></div></youdao_grammar_result><youdao-grammar-editor><div></div></youdao-grammar-editor>
</div>
</body>
</html>
