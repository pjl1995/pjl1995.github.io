<head>
    <title>Jinlong Peng</title>
    <meta name="author" content="Jinlong Peng">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta property="og:title" content="Jinlong Peng">
    <meta property="og:description" content="Senior Researcher, Tencent">
    <meta property="og:image" content="files/me.jpg">
    <meta property="og:url" content="https://jiangzhengkai.github.io/">
    <link rel="stylesheet" href="style.css">
</head>

<div class="header noselect">
    <div class="content row">
        <div class="header-profile-picture"></div>
        <div class="header-text">
            <div class="header-name">
                <h1>Jinlong Peng (彭瑾龙)</h1>
            </div>
            <div class="header-subtitle">
                Senior Researcher
            </div>
            <div class="header-links">
                <a class="btn" href="https://scholar.google.com.hk/citations?user=i5I-cIEAAAAJ&hl=zh-CN">Google Scholar</a> /
                <a class="btn" href="https://github.com/pjl1995">GitHub</a> /
                <a class="btn" href="https://zhihu.com/people/peng-jin-long-47">Zhihu</a> 
            </div>
        </div>
    </div>
</div>
<div class="content" style="padding-bottom: 48px;">
    <div>
        <p>
            I obtained the master's degree at 2019 and bachelor's degree at 2016 both from <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>, advised by <a href="https://weiyaolin.github.io/">Prof. Weiyao Lin</a>.
           <br><br>
           I am currently a Senior Researcher at <a href="https://open.youtu.qq.com/#/open">Tencent Youtu Lab</a>. My research interests are in multiple object tracking, visual object traking, video object segmentation, video instance segmentation, anomaly detection.
           <br><br>
           <strong>I am looking for highly motivated interns working on exciting computer vision projects based in Shanghai. If you are interested, please send me an email.</strong>
        </p>
    </div>
    <div>
        <h2 class="noselect">Publications</h2>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/ECCV2022_ProCA.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="">Prototypical Contrast Adaptation for Domain Adaptive Semantic Segmentation</a><br/>
                <span class="bold">Zhengkai Jiang</span>, Yuxi Li, Ceyuan Yang, Peng Gao, Yabiao Wang, Ying Tai, Chengjie Wang<br/>
                <span class="italic"><a href="https://eccv2022.ecva.net/">ECCV</a></span>, 2022<br/>
                <a class="btn btn-red" href="https://arxiv.org/pdf/2207.06654.pdf">paper</a>  / <a class="btn" href="https://github.com/jiangzhengkai/ProCA">code</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/AAAI2022_DIRL.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="">DIRL: Domain-invariant representation learning for generalizable semantic segmentation</a><br/>
                Qi Xu, Liang Yao, <span class="bold">Zhengkai Jiang</span>, Guannan Jiang, Wenqing Chu, Wenhui Han, Wei Zhang, Chengjie Wang, Ying Tai<br/>
                <span class="italic"><a href="https://aaai.org/Conferences/AAAI-22/">AAAI, Oral</a></span>, 2022<br/>
                <a class="btn btn-red" href="https://www.aaai.org/AAAI22Papers/AAAI-3574.XuQ.pdf">paper</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/ICCV2021_P2PNet.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Song_Rethinking_Counting_and_Localization_in_Crowds_A_Purely_Point-Based_Framework_ICCV_2021_paper.pdf">Rethinking Counting and Localization in Crowds:
                    A Purely Point-Based Framework</a><br/>
                Qingyu Song, Changan Wang, <span class="bold">Zhengkai Jiang</span>, Yabiao Wang, Ying Tai, Chengjie Wang, Jilin Li, Feiyue Huang, Yang Wu<br/>
                <span class="italic"><a href="https://iccv2021.thecvf.com">ICCV, Oral</a></span>, 2021<br/>
                <a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Song_Rethinking_Counting_and_Localization_in_Crowds_A_Purely_Point-Based_Framework_ICCV_2021_paper.pdf">paper</a> / <a class="btn" href="https://github.com/TencentYoutuResearch/CrowdCounting-P2PNet">code</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/NeurIPS2020_LFT-V2.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://proceedings.neurips.cc/paper/2020/file/2952351097998ac1240cb2ab7333a3d2-Paper.pdf">Rethinking Learnable Tree Filter for Generic Feature Transform</a><br/>
                Lin Song, Yanwei Li, <span class="bold">Zhengkai Jiang</span>, Zeming Li, Xiangyu Zhang, Hongbin Sun, Jian Sun, Nanning Zheng<br/>
                <span class="italic"><a href="https://nips.cc/">NeurIPS</a></span>, 2020<br/>
                <a class="btn btn-red" href="https://proceedings.neurips.cc/paper/2020/file/2952351097998ac1240cb2ab7333a3d2-Paper.pdf">paper</a> / <a class="btn" href="https://github.com/StevenGrove/LearnableTreeFilterV2">code</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/NeurIPS2020_DynamicHead.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://proceedings.neurips.cc/paper/2020/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf">Fine-Grained Dynamic Head for Object Detection</a><br/>
                Lin Song, Yanwei Li, <span class="bold">Zhengkai Jiang</span>, Zeming Li, Hongbin Sun, Jian Sun, Nanning Zheng<br/>
                <span class="italic"><a href="https://nips.cc/">NeurIPS</a></span>, 2020<br/>
                <a class="btn btn-red" href="https://proceedings.neurips.cc/paper/2020/file/7f6caf1f0ba788cd7953d817724c2b6e-Paper.pdf">paper</a> / <a class="btn" href="https://github.com/StevenGrove/DynamicHead">code</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/ECCV2020_LSTS.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://arxiv.org/pdf/1911.05253.pdf">Learning Where to Focus for Efficient Video Object Detection</a><br/>
                <span class="bold">Zhengkai Jiang</span>, Yu Liu, Ceyuan Yang, Jihao Liu, Peng Gao, Qian Zhang, Shiming Xiang, Chunhong Pan<br/>
                <span class="italic"><a href="https://eccv2022.ecva.net/">ECCV</a></span>, 2020<br/>
                <a class="btn btn-orange" href="https://jiangzhengkai.github.io/LSTS/">project page</a> / <a class="btn btn-red" href="https://arxiv.org/pdf/1911.05253.pdf">paper</a> / <a class="btn" href="https://github.com/jiangzhengkai/LSTS">code</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/CVPR2019_DFAF.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.pdf">Dynamic Fusion with Intra- and Inter-modality Attention Flow for Visual Question Answering</a><br/>
                Peng Gao, <span class="bold">Zhengkai Jiang</span>, Haoxuan You, Pan Lu, Steven Hoi, Xiaogang Wang, Hongsheng Li<br/>
                <span class="italic"><a href="https://cvpr2019.thecvf.com/">CVPR, Oral</a></span>, 2019<br/>
                <a class="btn btn-red" href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.pdf">Paper</a>
            </div>
        </div>
        <div class="publication row clearfix">
            <div class="row-media" style="background-image: url(papers/AAAI2019_LWDN.png);"></div>
            <div class="row-text">
                <a class="publication-title bold" href="https://ojs.aaai.org//index.php/AAAI/article/view/4871">Video Object Detection with Locally-Weightd Deformable Neighboors</a><br/>
                <span class="bold">Zhengkai Jiang</span>, Peng Gao, Chaoxu Guo, Qian Zhang, Shiming Xiang, Chunhong Pan<br/>
                <span class="italic"><a href="https://aaai.org/Conferences/AAAI-19/">AAAI</a></span>, 2019<br/>
                <a class="btn btn-red" href="https://ojs.aaai.org//index.php/AAAI/article/view/4871">Paper</a>
            </div>
        </div>
    </div>
    <div class="noselect">
        <a id="service"></a>
        <h2>Service</h2>
        Conference Reviewer:
        <p>
            <li>European Conference on Computer Vision (ECCV), 2022<br/></li>
            <li>International Conference on Machine Learning (ICML), 2022, 2023 <br/></li>
            <li>International Conference on Learning Representations (ICLR), 2022, 2023 <br/></li> 
            <li>Conference on Neural Information Processing Systems (NeurIPS), 2021, 2022 <br/></li> 
            <li>International Conference on Computer Vision (ICCV), 2021, 2023 <br/></li> 
            <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021, 2022, 2023<br/></li> 
            <li>AAAI Conference on Artificial Intelligence (AAAI), 2021, 2022, 2023<br/></li>
        </p>
        Journal Reviewer:
        <p>
            <li>International Journal of Computer Vision (IJCV)<br/></li>
            <li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) <br/></li>
            <li>IEEE Transactions on Circuits and Systems for Video Technology (TCVST) <br/></li>
        </p>
    </div>
    <div class="noselect">
        <a id="Honor"></a>
        <h2>Honor</h2>
        <p> 
            <li>1st of the Objects 365 Challenge, 2020</li>
            <li>1st of the NuScenes 3D Detection of CVPR WAD workshop, 2019</li>
            <li>1st of the Chinese Mathematics Competitions (1/6000+ in Liaoning Province), 2015, 2016</li> 
            <li>National Scholarship (Top 0.2% students in China), 2014, 2015, 2016</li>
        </p>
    </div>
    <div class="noselect">
        <a id="contact"></a>
        <h2>Contact</h2>
        You are very welcome to contact me. I can be contacted directly at <span class="bold">jeromepeng@tencent.com</span>
    </div>
</div>
